{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üé§ Audio PsyChat - Google Colab\n",
        "\n",
        "**FREE AI Psychological Counseling with Voice!**\n",
        "\n",
        "## üìã Setup (3 Steps):\n",
        "\n",
        "1. **Enable GPU**: Runtime ‚Üí Change runtime type ‚Üí **T4 GPU** ‚Üí Save\n",
        "2. **Upload**: `AudioPsyChat_Colab_Upload.zip` (124KB - use folder icon ‚Üê)\n",
        "3. **Run All**: Runtime ‚Üí Run all ‚Üí Wait 15 min\n",
        "\n",
        "---\n",
        "\n",
        "**Access Info:**\n",
        "- Look for the localtunnel URL in Cell 6 output (https://xxxxx.loca.lt)\n",
        "- Password shown in Cell 7\n",
        "- Add `/static` to URL to access interface\n",
        "\n",
        "**No AWS ‚Ä¢ No Billing ‚Ä¢ 100% FREE** üéâ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 1: Extract code and check GPU\n",
        "!unzip -q AudioPsyChat_Colab_Upload.zip 2>/dev/null || echo \"‚ö†Ô∏è Upload AudioPsyChat_Colab_Upload.zip first!\"\n",
        "import os\n",
        "print(\"‚úÖ Code ready!\" if os.path.exists('main.py') else \"‚ùå Upload zip and rerun!\")\n",
        "!nvidia-smi --query-gpu=name --format=csv,noheader || echo \"‚ùå Enable GPU!\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 2: Install system tools\n",
        "!apt-get update -qq && apt-get install -y -qq ffmpeg > /dev/null 2>&1\n",
        "print(\"‚úÖ System tools ready\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 3: Install Python packages (~10 min)\n",
        "print(\"üì¶ Installing packages (this takes ~10 minutes)...\")\n",
        "\n",
        "# Install core packages\n",
        "%pip install -q paddlepaddle-gpu\n",
        "%pip install -q fastapi uvicorn python-multipart\n",
        "%pip install -q transformers torch torchaudio\n",
        "%pip install -q numpy==1.24.4 scipy librosa soundfile\n",
        "%pip install -q huggingface-hub\n",
        "\n",
        "# Install PaddleSpeech dependencies with compatible versions\n",
        "%pip install -q aistudio-sdk==0.2.3\n",
        "%pip install -q paddlenlp==2.6.1\n",
        "%pip install -q paddleaudio==1.0.2\n",
        "%pip install -q paddlespeech==1.4.1\n",
        "\n",
        "print(\"‚úÖ All packages installed!\")\n",
        "print(\"‚ö†Ô∏è Some warnings above are OK - as long as this message shows, you're good!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4: Download models from HuggingFace (~7GB, 5-10 min)\n",
        "print(\"üì• Downloading PsyChat models (~7GB)...\")\n",
        "!huggingface-cli download qiuhuachuan/PsyChat --local-dir ./PsyChat --local-dir-use-symlinks False\n",
        "import os\n",
        "models = [f\"PsyChat/pytorch_model-0000{i}-of-00007.bin\" for i in range(1,8)]\n",
        "print(\"‚úÖ Downloaded!\" if all(os.path.exists(m) for m in models) else \"‚ö†Ô∏è Check above for errors\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 5: Start server (~2 min to load models)\n",
        "import subprocess, threading, time\n",
        "print(\"üöÄ Starting server (loading models takes 2-3 min)...\")\n",
        "threading.Thread(target=lambda: subprocess.run(['python', 'main.py']), daemon=True).start()\n",
        "time.sleep(120)  # Wait for models to load\n",
        "print(\"‚úÖ Server should be ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 6: Create public URL with localtunnel\n",
        "!npm install -g localtunnel -q\n",
        "print(\"üåê Creating public tunnel...\")\n",
        "print(\"Look for 'your url is: https://xxxxx.loca.lt' below:\")\n",
        "print(\"\")\n",
        "!lt --port 8086\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 7: Get your access info\n",
        "import requests\n",
        "pwd = requests.get('https://loca.lt/mytunnelpassword', timeout=5).text.strip()\n",
        "print(\"=\"*70)\n",
        "print(\"‚úÖ AUDIO PSYCHAT ACCESS INFO\")\n",
        "print(\"=\"*70)\n",
        "print(f\"üîë Password: {pwd}\")\n",
        "print(\"üìã URL: Copy the https://xxxxx.loca.lt URL from Cell 6 above\")\n",
        "print(\"    Add /static to the end\")\n",
        "print(\"\")\n",
        "print(\"üìù Steps: Click URL ‚Üí Enter password ‚Üí Access /static ‚Üí Allow mic ‚Üí Chat!\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚úÖ Done!\n",
        "\n",
        "Your Audio PsyChat is running!\n",
        "\n",
        "### üé§ How to Use:\n",
        "1. **Voice**: Click \"Record\" ‚Üí Speak ‚Üí \"Stop\"\n",
        "2. **Text**: Type and click \"Send\"\n",
        "\n",
        "### üí° Tips:\n",
        "- Keep Colab tab open\n",
        "- Session lasts ~12 hours\n",
        "- Rerun if disconnected (models cached = faster!)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
